<?xml version="1.0"?>
<section xmlns="http://docbook.org/ns/docbook" 
	 xmlns:xlink="http://www.w3.org/1999/xlink"
	 xml:id="quality.book">
  <info>
    <title>Source Code Quality</title>
    <date>February 13th, 2010</date>
  </info>
  
  <para>
    The quality of a software system relies fundamentally on dedicated and inventive contributors supported by  Quality is in many ways subjective. The quality in terms of usefulness relies a lot of trial and errors, the larger software ecosystem, human perceptions and a perfect market timing. There are unlikely efficient, reliable procedures and infrastructures to achieve this kind of quality so we will focus on the quality that can be achieved and mechanically inforced, that is software systems behaving as expected by the people who wrote the code. These fall in two categories: static analysis and runtime behavior. 
  </para>
  <section>
    <title>Conventions</title>
    <para>The purpose of conventions is to make it faster for developers to use pre-existing general knowledge and start contributing to specific projects they were unfamiliar with. Conventions also help create automated tools and an infrastructure to build code, run tests and generate status reports (as detailed in <link linkend="workspace.book">workspace</link>).</para>
    <section>
      <title>Code Layout</title>
    <para>Each project in fortylines source repository is organized as follow</para>
    <variablelist>
      <varlistentry>
	<term>index.xml</term>
	<listitem>
	  <para>Project description and inter-projects dependency information.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>Makefile</term>
	<listitem>
	  <para>GNU Makefile used to build and install a project files on the local system.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>data/</term>
	<listitem><para>Files necessary to build and run project executables but which are not considered source files.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>doc/</term>
	<listitem><para>General documentation for the project which cannot be extracted from the source files.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>include/</term>
	<listitem><para>Public header files (.hh, .tcc) that are installed in <link linkend="dws.book#includeDir">includeDir</link> (ex. /usr/local/include).</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>src/</term>
	<listitem><para>Source code in the form of C++ (.cc) and Python (.py) files.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>test/</term>
	<listitem><para>Unit tests for the project. The organization of a test/ sub-directory follows the organization of a project directory, though mostly consisting of Makefile, src/ and data/ directories.</para>
	</listitem>
      </varlistentry>
    </variablelist>
    <para>All files in fortylines source repository should respect the following conventions</para>
    <itemizedlist>
      <listitem><para>Each source file starts with a few license paragraphs.</para></listitem>
      <listitem><para>Identifiers use camelCase with a leading lowercase letter.</para></listitem>
      <listitem><para>Each file name follows the camelCase identifier convention.</para></listitem>
    </itemizedlist>
    <para>
      As projects grow in size, it becomes cumbersome to enforce conventions manually. As a result, the only convention that exist are the ones that can be checked and enforce by an automated tool as part of the build process.
    </para>
    <para>
      A checkstyle script runs through the top-level <link linkend="dws.book#srcTop">srcTop</link> and outputs a detailed report about projects broking those conventions.</para>    
    </section>
    <section>
      <title>Release Checklist</title>
      <para>It is not easy to realize when a project is of release quality. Planes do not take off before the captain verify every items on a list and checks them off. It is a very efficient and cost-effective way of insuring a certain level of quality. In the software world, as the cost of post-release workarounds and fixes can become enormous, it is wise to keep a simple, straightforward &quot;release checklist&quot; to thoroughly go through before any package is pushed onto the delivery channels. Having an explicit release checklist is an important step towards a consistent quality through releases. For example:</para>
      <itemizedlist>
	<listitem><para>General</para>
	  <itemizedlist>
	    <listitem><para>All unit tests pass</para></listitem>
	    <listitem><para>All source files have an appropriate license</para></listitem>
	    <!-- Remove hardcoded references (fortylines, "solutions", 
		 smirolo, etc. -->
	  </itemizedlist>
	</listitem>
	<listitem><para>C++ (.hh, .tcc, .cc)</para>
	  <itemizedlist>
	    <listitem><para>No std::cerr statements that can be accounted as debugging messages.</para></listitem>
	    <listitem><para>No "#if 0" nor "#if 1" without a blessed &quot;todo&quot; comment.</para></listitem>
	    <listitem><para>compile with no warnings when using -Wall compiler command line flag</para></listitem>
	  </itemizedlist>
	</listitem>
	<listitem><para>Python (.py)</para>
	  <itemizedlist>
	    <listitem><para>No "if None:" without a blessed &quot;todo&quot; comment.</para></listitem>
	  </itemizedlist>
	</listitem>
	<listitem><para>Documentation (.docbook)</para>
	  <itemizedlist>
	    <listitem><para>No error when run through the spellchecker</para></listitem>
	  </itemizedlist>
	</listitem>
	<listitem><para>HTML (.css, .template)</para>
	  <itemizedlist>
	    <listitem><para>Correct display of each template on Firefox, Safari and IE8.</para></listitem>
	  </itemizedlist>
	</listitem>
      </itemizedlist>
    </section>
  </section>
  
  <section>
    <title>Unit tests</title>
    <para>The purpose of unit tests is to insure first that functionality is implemented correctly. Later in the life cycle of a project, unit tests are often relabeled regression tests and insure that changes to the source code did not break existing functionality.</para>
    <para>The definition of functional and regression tests are very often used interchangeably because a functional test can serve as the base for a regression test as much as a regression test can be used to validate functionality.</para> 
    <para>For our purpose here, the major distinction between a functional and regression test is how they were originally created. The developper of a functional test has explicitely thought about the passing and failing conditions and written explicit statements for them in the source code that is checked into the repository. The developper of a regression test typically used the build framework to trigger comparison of different runs of the same program.</para> 
    <para>As such functional tests usually result in source code while regression tests result in makefile rules. Functional tests also typically result in self-contained executables while regression tests rely on external data sets usually stored outside the version controled repository.</para>
    <informaltable>
      <tr><th>functional</th><th>regression</th></tr>
      <tr><td>explicit pass conditions</td><td>output comparison</td></tr>
      <tr><td>source code</td><td>makefiles</td></tr>
      <tr><td>self-contained</td><td>rely on external data sets</td></tr>
    </informaltable>
    <para> Unit tests will typically start breaking and become deprecated as a project moves forward. As a result, relevant unit tests are the ones that can be run by an automated tool as part of the <link linkend="/services/doc/usecases.book#snapshotBuilds">build process</link>.</para>
  </section>
</section>

